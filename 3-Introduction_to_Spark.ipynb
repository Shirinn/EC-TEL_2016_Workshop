{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Spark\n",
    "\n",
    "## Introduction to Resiliant Distributed Datasets (RDD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "\n",
    "* Spark is a distributed computing framework for big data. \n",
    "* Clusters of worker machines operate on Resiliant Distributed Datasets (RDDs) in paralell. \n",
    "* Spark is optimized to utilized worker memory as much as possible, allowing for fast computation on large datasets.\n",
    "\n",
    "<img src=\"figs/RDD_1.png\">\n",
    "#### A spark driver, either through an application or shell, connects to a cluster consisting of worker machines. (Databricks Workshop 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "\n",
    "* RDDs are collections of data either from a central source which is then parallelized (file on local machine) or from a distributed data store (HDFS, Cassandra etc).\n",
    "* RDDs can consist of common data types and arbitrary objects.\n",
    "* An RDD is split between several partitions and distributed to the different worker machines.\n",
    "<img src=\"figs/RDD_2.png\">\n",
    "#### Large dataset partitioned between different worker machines in a Spark cluster (Databricks Workshop 2015) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "\n",
    "* Example RDD consisting of logging data\n",
    "\n",
    "<img src=\"figs/RDD_3.png\">\n",
    "#### (Databricks Workshop 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "\n",
    "* Creating an RDD from a collection of data on the driver and distributing them to the worker machines\n",
    "\n",
    "<img src=\"figs/RDD_4.png\">\n",
    "#### (Databricks Workshop 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ParallelCollectionRDD[0] at parallelize at PythonRDD.scala:423\n",
      "3\n",
      "fish\n",
      "['fish', 'cats', 'dogs']\n"
     ]
    }
   ],
   "source": [
    "# Create RDD from a python list\n",
    "wordsRDD = sc.parallelize([\"fish\", \"cats\", \"dogs\"])\n",
    "\n",
    "# View object type\n",
    "print(wordsRDD)\n",
    "\n",
    "# Get number of objects in RDD\n",
    "print(wordsRDD.count())\n",
    "\n",
    "# Get the first object in the RDD\n",
    "print(wordsRDD.first())\n",
    "\n",
    "# Collect all the objects in the RDD from Spark back to driver (this notebook)\n",
    "print(wordsRDD.collect())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "\n",
    "* Creating an RDD from a file\n",
    "  * Can come from local machine (small files)\n",
    "  * Can read files directly from HDFS and Cassandra\n",
    "    * example: > newRDD = sc.textFile(\"hdfs://localhost:9000/user/data/file.txt\")\n",
    "\n",
    "<img src=\"figs/RDD_5.png\">\n",
    "#### (Databricks Workshop 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a total of 22933 lines in Moby Dick\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[u'MOBY DICK; OR THE WHALE ',\n",
       " u'',\n",
       " u'by Herman Melville',\n",
       " u'',\n",
       " u'',\n",
       " u'',\n",
       " u'',\n",
       " u'ETYMOLOGY.',\n",
       " u'',\n",
       " u'(Supplied by a Late Consumptive Usher to a Grammar School)',\n",
       " u'',\n",
       " u'The pale Usher--threadbare in coat, heart, body, and brain; I see him',\n",
       " u'now.  He was ever dusting his old lexicons and grammars, with a queer',\n",
       " u'handkerchief, mockingly embellished with all the gay flags of all the',\n",
       " u'known nations of the world.  He loved to dust his old grammars; it',\n",
       " u'somehow mildly reminded him of his mortality.',\n",
       " u'',\n",
       " u'\"While you take in hand to school others, and to teach them by what',\n",
       " u'name a whale-fish is to be called in our tongue leaving out, through',\n",
       " u'ignorance, the letter H, which almost alone maketh the signification',\n",
       " u'of the word, you deliver that which is not true.\" --HACKLUYT',\n",
       " u'',\n",
       " u'\"WHALE. ... Sw. and Dan. HVAL.  This animal is named from roundness',\n",
       " u'or rolling; for in Dan. HVALT is arched or vaulted.\" --WEBSTER\\'S',\n",
       " u'DICTIONARY',\n",
       " u'',\n",
       " u'\"WHALE. ... It is more immediately from the Dut. and Ger. WALLEN;',\n",
       " u'A.S. WALW-IAN, to roll, to wallow.\" --RICHARDSON\\'S DICTIONARY',\n",
       " u'',\n",
       " u'KETOS,               GREEK.',\n",
       " u'CETUS,               LATIN.',\n",
       " u'WHOEL,               ANGLO-SAXON.',\n",
       " u'HVALT,               DANISH.',\n",
       " u'WAL,                 DUTCH.',\n",
       " u'HWAL,                SWEDISH.',\n",
       " u'WHALE,               ICELANDIC.',\n",
       " u'WHALE,               ENGLISH.',\n",
       " u'BALEINE,             FRENCH.',\n",
       " u'BALLENA,             SPANISH.',\n",
       " u'PEKEE-NUEE-NUEE,     FEGEE.',\n",
       " u'PEKEE-NUEE-NUEE,     ERROMANGOAN.',\n",
       " u'',\n",
       " u'',\n",
       " u'',\n",
       " u'',\n",
       " u'EXTRACTS (Supplied by a Sub-Sub-Librarian).',\n",
       " u'',\n",
       " u'It will be seen that this mere painstaking burrower and grub-worm of',\n",
       " u'a poor devil of a Sub-Sub appears to have gone through the long',\n",
       " u'Vaticans and street-stalls of the earth, picking up whatever random']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in Moby Dick text file (reads in one line per RDD entry)\n",
    "mobyDickRDD = sc.textFile(\"./data/MobyDick.txt\")\n",
    "\n",
    "# Count how many lines are in RDD\n",
    "print(\"There is a total of %d lines in Moby Dick\" % mobyDickRDD.count())\n",
    "\n",
    "# Take first 5 lines from RDD\n",
    "mobyDickRDD.take(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "\n",
    "* Typical workflow\n",
    "  * Data is read from external sources (HDFS, Cassandra, local file...) into an RDD\n",
    "  * Transformations are performed on RDD to create new RDDs\n",
    "    * In this example, the main RDD is filtered to create an RDD which only contains Error messages\n",
    "\n",
    "<img src=\"figs/RDD_6.png\">\n",
    "#### (Databricks Workshop 2015)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "\n",
    "* Filtered RDDs can be coalesced to reduce the number of partitions which make up that RDD\n",
    "  * Used when filtered RDDs become sparse compared to their parent RDD\n",
    "\n",
    "<img src=\"figs/RDD_7.png\">\n",
    "#### (Databricks Workshop 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# The number of paritions for a RDD can be specified when RDD is created\n",
    "# This is automatically done if no parameter is passed\n",
    "N_partitions = 4\n",
    "team = sc.parallelize([\"Al\", \"Ani\", \"Jackie\", \"Lalitha\", \"Mark\", \"Neil\", \"Nick\", \"Shirin\"], N_partitions)\n",
    "print(team.getNumPartitions())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "***\n",
    "\n",
    "* Standard workflow for a Spark application\n",
    "\n",
    "<img src=\"figs/RDD_8.png\">\n",
    "#### (Databricks Workshop 2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
